{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.data.size())\n",
    "print(test_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://www.kaggle.com/code/pankajj/fashion-mnist-with-pytorch-93-accuracy\n",
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_samples(dataloader):\n",
    "    rows = 8\n",
    "    columns = 8\n",
    "    fig = plt.figure(figsize=(10, 10), layout=\"constrained\")\n",
    "    for X, y in dataloader:\n",
    "        for i, (image, label) in enumerate(zip(X, y)):\n",
    "            fig.add_subplot(rows, columns, i+1)\n",
    "            plt.axis('off')\n",
    "            plt.title(output_label(label.item()), size=\"small\")\n",
    "            plt.imshow(image[0].detach().numpy(), cmap='gray')\n",
    "        break\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "plot_first_samples(test_dataloader)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward Neural Network\n",
    "\n",
    "# model architecture from: https://www.kaggle.com/code/pankajj/fashion-mnist-with-pytorch-93-accuracy\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_shape : torch.Size, hidden_sizes : list[int], num_classes : int, activation_function, loss_fn):\n",
    "        super().__init__()\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_function,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation_function,\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential( # todo use hidden sizes\n",
    "            nn.Linear(64*6*6, 600),\n",
    "            nn.Dropout(0.25),\n",
    "            activation_function,\n",
    "            nn.Linear(600, 120),\n",
    "            activation_function,\n",
    "            nn.Linear(120, num_classes) # no softmax necessary\n",
    "        )\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def train_network(self, dataloader : DataLoader, optimizer : torch.optim.Optimizer):\n",
    "        size = len(dataloader.dataset)\n",
    "        self.train()\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            y_pred = self.forward(X)\n",
    "            loss = self.loss_fn(y_pred, F.one_hot(y, self.num_classes).type(y_pred.dtype))\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    def test(self, dataloader : DataLoader):\n",
    "        num_batches = len(dataloader)\n",
    "        self.eval()\n",
    "        test_loss = 0\n",
    "        num_right = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_pred  = self.forward(X)\n",
    "                test_loss += self.loss_fn(y_pred , F.one_hot(y, self.num_classes).type(y_pred.dtype)).item()\n",
    "                num_correct += (torch.argmax(y_pred, dim=1) == y).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        accuracy = num_correct / len(dataloader.dataset)\n",
    "        print(f\"Test Error: Avg loss: {test_loss:>8f} Accuracy: {accuracy:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity()\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.310787  [   64/60000]\n",
      "loss: 1.647881  [ 6464/60000]\n",
      "loss: 1.126427  [12864/60000]\n",
      "loss: 1.128337  [19264/60000]\n",
      "loss: 0.939857  [25664/60000]\n",
      "loss: 0.923860  [32064/60000]\n",
      "loss: 0.843552  [38464/60000]\n",
      "loss: 0.752672  [44864/60000]\n",
      "loss: 0.761260  [51264/60000]\n",
      "loss: 0.712886  [57664/60000]\n",
      "Test Error: Avg loss: 0.705627 Accuracy: 0.759600 \n",
      "\n",
      "Done!\n",
      "Sigmoid()\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.350827  [   64/60000]\n",
      "loss: 2.329164  [ 6464/60000]\n",
      "loss: 2.341285  [12864/60000]\n",
      "loss: 2.334251  [19264/60000]\n",
      "loss: 2.287128  [25664/60000]\n",
      "loss: 2.315415  [32064/60000]\n",
      "loss: 2.293931  [38464/60000]\n",
      "loss: 2.302391  [44864/60000]\n",
      "loss: 2.304707  [51264/60000]\n",
      "loss: 2.301793  [57664/60000]\n",
      "Test Error: Avg loss: 2.301309 Accuracy: 0.100000 \n",
      "\n",
      "Done!\n",
      "ReLU()\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306205  [   64/60000]\n",
      "loss: 2.160832  [ 6464/60000]\n",
      "loss: 1.960919  [12864/60000]\n",
      "loss: 1.868050  [19264/60000]\n",
      "loss: 1.625401  [25664/60000]\n",
      "loss: 1.500942  [32064/60000]\n",
      "loss: 1.344418  [38464/60000]\n",
      "loss: 1.196783  [44864/60000]\n",
      "loss: 1.185483  [51264/60000]\n",
      "loss: 1.016325  [57664/60000]\n",
      "Test Error: Avg loss: 0.970750 Accuracy: 0.741800 \n",
      "\n",
      "Done!\n",
      "SELU()\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.478244  [   64/60000]\n",
      "loss: 1.545459  [ 6464/60000]\n",
      "loss: 1.035689  [12864/60000]\n",
      "loss: 1.034132  [19264/60000]\n",
      "loss: 0.864013  [25664/60000]\n",
      "loss: 0.903215  [32064/60000]\n",
      "loss: 0.751715  [38464/60000]\n",
      "loss: 0.690223  [44864/60000]\n",
      "loss: 0.743669  [51264/60000]\n",
      "loss: 0.669767  [57664/60000]\n",
      "Test Error: Avg loss: 0.650080 Accuracy: 0.773300 \n",
      "\n",
      "Done!\n",
      "ELU(alpha=1.0)\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.344171  [   64/60000]\n",
      "loss: 1.957955  [ 6464/60000]\n",
      "loss: 1.615997  [12864/60000]\n",
      "loss: 1.457496  [19264/60000]\n",
      "loss: 1.221440  [25664/60000]\n",
      "loss: 1.205425  [32064/60000]\n",
      "loss: 1.049542  [38464/60000]\n",
      "loss: 0.931359  [44864/60000]\n",
      "loss: 0.978117  [51264/60000]\n",
      "loss: 0.843918  [57664/60000]\n",
      "Test Error: Avg loss: 0.822604 Accuracy: 0.739700 \n",
      "\n",
      "Done!\n",
      "LeakyReLU(negative_slope=0.01)\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.283996  [   64/60000]\n",
      "loss: 2.179316  [ 6464/60000]\n",
      "loss: 2.058793  [12864/60000]\n",
      "loss: 1.960404  [19264/60000]\n",
      "loss: 1.739844  [25664/60000]\n",
      "loss: 1.622620  [32064/60000]\n",
      "loss: 1.386641  [38464/60000]\n",
      "loss: 1.244134  [44864/60000]\n",
      "loss: 1.208131  [51264/60000]\n",
      "loss: 1.054992  [57664/60000]\n",
      "Test Error: Avg loss: 1.017347 Accuracy: 0.734500 \n",
      "\n",
      "Done!\n",
      "SiLU()\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307904  [   64/60000]\n",
      "loss: 2.281688  [ 6464/60000]\n",
      "loss: 2.218082  [12864/60000]\n",
      "loss: 2.179401  [19264/60000]\n",
      "loss: 2.113024  [25664/60000]\n",
      "loss: 2.056385  [32064/60000]\n",
      "loss: 1.913924  [38464/60000]\n",
      "loss: 1.833385  [44864/60000]\n",
      "loss: 1.685012  [51264/60000]\n",
      "loss: 1.490606  [57664/60000]\n",
      "Test Error: Avg loss: 1.491936 Accuracy: 0.641900 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Train Classifier (SGD)\n",
    "size = torch.Size((1,28,28))\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "classifiers_sgd : dict[str, Classifier] = {}\n",
    "for activation_function in [nn.Identity(), nn.Sigmoid(), nn.ReLU(), nn.SELU(), nn.ELU(), nn.LeakyReLU(), nn.SiLU()]:\n",
    "    classifier = Classifier(size, [], num_classes, activation_function, nn.CrossEntropyLoss()).to(device)\n",
    "    optimizer = torch.optim.SGD(classifier.parameters(), lr=1e-3)\n",
    "    print(str(activation_function))\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        classifier.train_network(train_dataloader, optimizer)\n",
    "        classifier.test(test_dataloader)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    classifiers_sgd[str(activation_function)] = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Identity()\n",
      "Test Error: Avg loss: 0.705627 Accuracy: 0.759600 \n",
      "\n",
      "Name: Sigmoid()\n",
      "Test Error: Avg loss: 2.301309 Accuracy: 0.100000 \n",
      "\n",
      "Name: ReLU()\n",
      "Test Error: Avg loss: 0.970750 Accuracy: 0.741800 \n",
      "\n",
      "Name: SELU()\n",
      "Test Error: Avg loss: 0.650080 Accuracy: 0.773300 \n",
      "\n",
      "Name: ELU(alpha=1.0)\n",
      "Test Error: Avg loss: 0.822604 Accuracy: 0.739700 \n",
      "\n",
      "Name: LeakyReLU(negative_slope=0.01)\n",
      "Test Error: Avg loss: 1.017347 Accuracy: 0.734500 \n",
      "\n",
      "Name: SiLU()\n",
      "Test Error: Avg loss: 1.491936 Accuracy: 0.641900 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in classifiers_sgd.items():\n",
    "    print(f\"Name: {name}\")\n",
    "    classifier.test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classified_first_samples(dataloader, model):\n",
    "    rows = 8\n",
    "    columns = 8\n",
    "    fig = plt.figure(figsize=(10, 10), layout=\"constrained\")\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y_pred = torch.argmax(model.forward(X.to(device)), dim=1).to('cpu')\n",
    "            for i, (image, true_label, predicted_label) in enumerate(zip(X, y, y_pred)):\n",
    "                fig.add_subplot(rows, columns, i+1)\n",
    "                plt.axis('off')\n",
    "                plt.title(output_label(predicted_label.item()) + (\"\\nCorrect: \" + output_label(true_label) if predicted_label != true_label else \"\"),\n",
    "                          color=\"green\" if predicted_label == true_label else \"red\",\n",
    "                          size=\"small\")\n",
    "                plt.imshow(image[0].detach().numpy(), cmap='gray')\n",
    "            break\n",
    "\n",
    "for name, classifier in classifiers_sgd.items():\n",
    "    print(name)\n",
    "    plot_classified_first_samples(test_dataloader, classifier)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy_per_class(dataloader, model):\n",
    "    num_batches = len(dataloader)\n",
    "    self.eval()\n",
    "    test_loss = 0\n",
    "    num_correct = [0 for _ in range(num_classes)]\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred  = self.forward(X)\n",
    "            num_right += (torch.argmax(y_pred, dim=1) == y).sum().item()\n",
    "    accuracy = num_right / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix():\n",
    "    pass # research how to do that"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
